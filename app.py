import os
import re
import streamlit as st
import fitz  # PyMuPDF
import matplotlib.pyplot as plt
from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification
import torch

# ------------------------
# RÃ©sumÃ© automatique (modÃ¨le plus lÃ©ger)
# ------------------------

@st.cache_resource
def load_summarizer():
    return pipeline("summarization", model="sshleifer/distilbart-cnn-12-3")  # version + lÃ©gÃ¨re

def summarize_text(text, max_tokens=1024):
    summarizer = load_summarizer()
    # Limiter Ã  1 ou 2 chunks max pour Ã©viter surcharge CPU/mÃ©moire
    chunks = [text[i:i+1000] for i in range(0, min(len(text), 2000), 1000)]
    summary = ""
    for chunk in chunks:
        res = summarizer(chunk, max_length=100, min_length=30, do_sample=False)
        summary += res[0]['summary_text'] + " "
    return summary.strip()

# ------------------------
# Extraction des donnÃ©es chiffrÃ©es
# ------------------------

def extract_numbers(text):
    pattern = r"\b(?:\d{1,3}(?:[\.,]\d{3})*|\d+)(?:[%â‚¬$]?| [A-Za-z]*)\b"
    matches = re.findall(pattern, text)
    return sorted(set(matches), key=lambda x: text.find(x))

# ------------------------
# DÃ©tection IA avec Roberta (utiliser 1 seul modÃ¨le en mÃ©moire)
# ------------------------

@st.cache_resource
def load_ai_detector():
    tokenizer = AutoTokenizer.from_pretrained("roberta-base-openai-detector")
    model = AutoModelForSequenceClassification.from_pretrained("roberta-base-openai-detector")
    model.eval()
    return tokenizer, model

def detect_ai_generated_text(text):
    tokenizer, model = load_ai_detector()
    short_text = text[:1000]  # RÃ©duire la longueur du texte pour le modÃ¨le
    inputs = tokenizer(short_text, return_tensors="pt", truncation=True, max_length=512)
    with torch.no_grad():
        outputs = model(**inputs)
        probs = torch.softmax(outputs.logits, dim=1).squeeze()
    return float(probs[1]), float(probs[0])

# ------------------------
# Extraction du texte PDF
# ------------------------

def extract_text_from_pdf(pdf_file):
    text = ""
    with fitz.open(stream=pdf_file.read(), filetype="pdf") as doc:
        for page in doc:
            text += page.get_text()
            if len(text) > 3000:
                break  # Limiter l'extraction Ã  3000 caractÃ¨res max
    return text

# ------------------------
# Interface utilisateur
# ------------------------

st.set_page_config(page_title="DÃ©tecteur IA PDF", page_icon="ğŸ¤–", layout="wide")
st.title("ğŸ“„ğŸ§  DÃ©tecteur de texte gÃ©nÃ©rÃ© par l'IA")

uploaded_file = st.sidebar.file_uploader("ğŸ“¤ TÃ©lÃ©versez un fichier PDF", type="pdf")

if not uploaded_file:
    image_path = os.path.join("assets", "image.png")
    if os.path.exists(image_path):
        st.image(image_path, use_container_width=True)
    else:
        st.warning("âš ï¸ Image d'accueil non trouvÃ©e.")
    st.markdown("""
    ### Bienvenue dans l'application de dÃ©tection IA ğŸ§ ğŸ“„  
    ğŸ‘‰ TÃ©lÃ©versez un fichier PDF via le menu latÃ©ral pour commencer.
    """)

if uploaded_file:
    st.success("âœ… Fichier chargÃ© avec succÃ¨s.")

    with st.spinner("ğŸ“š Extraction du texte..."):
        text = extract_text_from_pdf(uploaded_file)

    if not text.strip():
        st.error("âŒ Aucun texte dÃ©tectÃ©.")
    else:
        with st.spinner("ğŸ¤– Analyse du contenu..."):
            ai_score, human_score = detect_ai_generated_text(text)

        st.subheader("ğŸ§¾ RÃ©sultat de l'analyse")
        st.metric("ProbabilitÃ© IA", f"{ai_score * 100:.2f} %")

        fig, ax = plt.subplots()
        ax.pie([ai_score, human_score], labels=['IA', 'Humain'], autopct='%1.1f%%',
               colors=['#ff4b4b', '#1f77b4'], startangle=90, wedgeprops=dict(width=0.4))
        ax.set_title("DegrÃ© de gÃ©nÃ©ration IA")
        st.pyplot(fig)

        st.subheader("ğŸ¯ InterprÃ©tation")
        if ai_score >= 0.8:
            st.markdown("### ğŸ”´ TrÃ¨s Ã‰levÃ© : TrÃ¨s probablement gÃ©nÃ©rÃ© par une IA (â‰¥ 80%)")
        elif ai_score >= 0.5:
            st.markdown("### ğŸŸ¡ Ã‰levÃ© : Probablement gÃ©nÃ©rÃ© par une IA (50â€“80%)")
        elif ai_score >= 0.15:
            st.markdown("### ğŸ”µ ModÃ©rÃ© : Peut contenir des Ã©lÃ©ments IA (15â€“50%)")
        else:
            st.markdown("### ğŸŸ¢ Faible : TrÃ¨s probablement rÃ©digÃ© par un humain (< 15%)")

        with st.expander("ğŸ§  RÃ©sumÃ© automatique du texte"):
            with st.spinner("âœï¸ RÃ©sumÃ© en cours..."):
                summary = summarize_text(text)
            st.write(summary)

        with st.expander("ğŸ“Š DonnÃ©es clÃ©s dÃ©tectÃ©es"):
            numbers = extract_numbers(text)
            if numbers:
                st.write(", ".join(numbers))
            else:
                st.info("Aucune donnÃ©e chiffrÃ©e trouvÃ©e.")

        with st.expander("ğŸ“ AperÃ§u du texte analysÃ©"):
            st.text_area("Contenu (extrait)", text[:1500], height=300)
